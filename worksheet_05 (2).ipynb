{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K29ChSADN9VR"
      },
      "source": [
        "# Worksheet 05\n",
        "\n",
        "Name:  shivacharan oruganti\n",
        "UID:  U55255882\n",
        "\n",
        "### Topics\n",
        "\n",
        "- Cost Functions\n",
        "- Kmeans\n",
        "\n",
        "### Cost Function\n",
        "\n",
        "Solving Data Science problems often starts by defining a metric with which to evaluate solutions were you able to find some. This metric is called a cost function. Data Science then backtracks and tries to find a process / algorithm to find solutions that can optimize for that cost function.\n",
        "\n",
        "For example suppose you are asked to cluster three points A, B, C into two non-empty clusters. If someone gave you the solution `{A, B}, {C}`, how would you evaluate that this is a good solution?\n",
        "\n",
        "Notice that because the clusters need to be non-empty and all points must be assigned to a cluster, it must be that two of the three points will be together in one cluster and the third will be alone in the other cluster.\n",
        "\n",
        "In the above solution, if A and B are closer than A and C, and B and C, then this is a good solution. The smaller the distance between the two points in the same cluster (here A and B), the better the solution. So we can define our cost function to be that distance (between A and B here)!\n",
        "\n",
        "The algorithm / process would involve clustering together the two closest points and put the third in its own cluster. This process optimizes for that cost function because no other pair of points could have a lower distance (although it could equal it)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_V9Z9ABN9VV"
      },
      "source": [
        "### K means\n",
        "\n",
        "a) (1-dimensional clustering) Walk through Lloyd's algorithm step by step on the following dataset:\n",
        "\n",
        "`[0, .5, 1.5, 2, 6, 6.5, 7]` (note: each of these are 1-dimensional data points)\n",
        "\n",
        "Given the initial centroids:\n",
        "\n",
        "`[0, 2]`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVx0ZWQ0N9VV"
      },
      "source": [
        "Step 1: Assignment\n",
        "\n",
        "In the assignment step, we assign each data point to the nearest centroid.\n",
        "\n",
        "For the first centroid (0), the closest data points are [0, 0.5, 1.5].\n",
        "For the second centroid (2), the closest data points are [2].\n",
        "So, the initial clusters are:\n",
        "Cluster 1: [0, 0.5, 1.5]\n",
        "Cluster 2: [2, 6, 6.5, 7]\n",
        "\n",
        "Step 2: Update Centroids\n",
        "\n",
        "In the update step, we calculate the mean of each cluster and update the centroids accordingly.\n",
        "\n",
        "For Cluster 1, the mean is (0 + 0.5 + 1.5) / 3 = 1.0. So, the new centroid for Cluster 1 is 1.0.\n",
        "For Cluster 2, the mean is (2 + 6 + 6.5 + 7) / 4 = 5.875. So, the new centroid for Cluster 2 is 5.875.\n",
        "\n",
        "Step 3: Repeat\n",
        "\n",
        "We repeat the assignment and update steps until convergence. In this case, you can see that the centroids have converged to [1.0, 5.875], and the assignment of data points doesn't change anymore. So, the final clusters are:\n",
        "\n",
        "Cluster 1: [0, 0.5, 1.5]\n",
        "Cluster 2: [2, 6, 6.5, 7]\n",
        "\n",
        "The centroids [1.0, 5.875] represent the means of these clusters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpB0k1elN9VV"
      },
      "source": [
        "b) Describe in plain english what the cost function for k means is."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sono8trdN9VV"
      },
      "source": [
        "The cost function for k-means measures how well the data points in the dataset are grouped around their cluster centers. It calculates the total squared distance between each data point and the centroid of the cluster it belongs to, summing up these distances for all data points and clusters. This cost, called the \"within-cluster sum of squares,\" quantifies how tightly the data points are clustered within their respective groups. The goal of k-means is to minimize this cost, which means finding cluster assignments and centroids that result in compact and well-defined clusters for your data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBjxR754N9VV"
      },
      "source": [
        "c) For the same number of clusters K, why could there be very different solutions to the K means algorithm on a given dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgMbr3gLN9VV"
      },
      "source": [
        "It is because of initialization Sensitivity, Local Minima, Data Distribution, Outliers, and Convergence Criteria of the K means algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pbdNzAHN9VV"
      },
      "source": [
        "d) Does Lloyd's Algorithm always converge? Why / why not?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kkb723NDN9VW"
      },
      "source": [
        "Lloyd's Algorithm for k-means clustering does guarantee convergence to a local minimum of the cost function, but it does not guarantee convergence to the global minimum. The guaranteed convergence is to a local minimum because the algorithm iteratively minimizes the within-cluster sum of squares or a similar cost function. During each iteration, it reduces this cost function, which ensures that the algorithm will eventually stop and converge to a solution. However, because the k-means optimization problem is non-convex and can have multiple local minima, there is no guarantee that the solution found is the global minimum, which would be the best possible clustering solution. The final result can depend on the initial placement of centroids and other factors, potentially leading to suboptimal clusterings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_25NzMkN9VW"
      },
      "source": [
        "e) Follow along in class the implementation of Kmeans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5gBTOz9qN9VW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image as im\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.datasets as datasets\n",
        "\n",
        "centers = [[0, 0], [2, 2], [-3, 2], [2, -4]]\n",
        "X, _ = datasets.make_blobs(n_samples=300, centers=centers, cluster_std=1, random_state=0)\n",
        "# print(X)\n",
        "\n",
        "class KMeans():\n",
        "\n",
        "    def __init__(self, data, k):\n",
        "        self.data = data\n",
        "        self.k = k\n",
        "        self.assignment = [-1 for _ in range(len(data))]\n",
        "        self.snaps = []\n",
        "\n",
        "    def snap(self, centers):\n",
        "        # print(5)\n",
        "        TEMPFILE = \"temp.png\"\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.scatter(X[:, 0], X[:, 1], c=self.assignment)\n",
        "        ax.scatter(centers[:,0], centers[:, 1], c='r')\n",
        "        fig.savefig(TEMPFILE)\n",
        "        # print(TEMPFILE)\n",
        "        plt.close()\n",
        "        self.snaps.append(im.fromarray(np.asarray(im.open(TEMPFILE))))\n",
        "\n",
        "    def initialize(self):\n",
        "        return self.data[np.random.choice(range(len(self.data)),self.k, replace = False)]\n",
        "\n",
        "    def distance(self,x,y):\n",
        "        return  np.linalg.norm(x-y)\n",
        "\n",
        "\n",
        "    def assign(self, centers):\n",
        "        for i in range(len(self.data)):\n",
        "            delta = [float('inf'),0]\n",
        "            for j in range(len(centers)):\n",
        "                distance = self.distance(centers[j],self.data[i])\n",
        "                if distance<delta[0]:\n",
        "                    delta[0] = distance\n",
        "                    delta[1] = j\n",
        "\n",
        "            self.assignment[i] = delta[1]\n",
        "\n",
        "\n",
        "\n",
        "    def get_centers(self):\n",
        "        centers = []\n",
        "\n",
        "        for i in set(self.assignment):\n",
        "            cluster = []\n",
        "\n",
        "            for j in range(len(self.data)):\n",
        "\n",
        "                if self.assignment[j] ==i:\n",
        "                    cluster.append(self.data[j])\n",
        "            x = 0\n",
        "            y = 0\n",
        "            for delta in range(len(cluster)):\n",
        "                x+=cluster[delta][0]\n",
        "                y+=cluster[delta][1]\n",
        "            centers.append([x/len(cluster), y/len(cluster)])\n",
        "\n",
        "        return np.array(centers)\n",
        "\n",
        "\n",
        "    def is_diff_centers(self,centers, new_centers):\n",
        "        n = len(centers)\n",
        "        flag = 0\n",
        "        for i in range(n):\n",
        "            if centers[i][0]!=new_centers[i][0]:\n",
        "                flag = 1\n",
        "\n",
        "        if flag ==1:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "\n",
        "\n",
        "    def lloyds(self):\n",
        "        # ...\n",
        "        # print(15)\n",
        "        centers = self.initialize()\n",
        "        self.assign(centers)\n",
        "        self.snap(centers)\n",
        "        new_centers = self.get_centers()\n",
        "\n",
        "        while self.is_diff_centers(centers,new_centers):\n",
        "            # print(10)\n",
        "\n",
        "            self.assign(new_centers)\n",
        "            centers = new_centers\n",
        "            self.snap(centers)\n",
        "            new_centers = self.get_centers()\n",
        "\n",
        "\n",
        "        return\n",
        "\n",
        "\n",
        "\n",
        "kmeans = KMeans(X, 4)\n",
        "kmeans.lloyds()\n",
        "images = kmeans.snaps\n",
        "# print(kmeans.snaps)\n",
        "\n",
        "images[0].save(\n",
        "    'kmeans.gif',\n",
        "    optimize=False,\n",
        "    save_all=True,\n",
        "    append_images=images[1:],\n",
        "    loop=0,\n",
        "    duration=500\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VdVTt4xQQC4G"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.1"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "76ca05dc3ea24b2e3b98cdb7774adfbb40773424bf5109b477fd793f623715af"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}